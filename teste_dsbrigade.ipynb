{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take only necessary columns\n",
    "item_columns = [\"DS_ITEM\", \"VL_UNITARIO_HOMOLOGADO\", \"NR_LICITACAO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Completed\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "#Defining the zip file URL\n",
    "url = 'http://dados.tce.rs.gov.br/dados/licitacon/licitacao/ano/2016.csv.zip'\n",
    "\n",
    "# Split URL to get the file name\n",
    "filename = url.split('/')[-1]\n",
    "\n",
    "# Downloading the file by sending the request to the URL\n",
    "req= requests.get(url)\n",
    "print('Downloading Completed')\n",
    "\n",
    "# extracting the zip file contents\n",
    "zipfile = zipfile.ZipFile(BytesIO(req.content))\n",
    "zipfile.extract(member='item.csv',\n",
    "                path='/home/rafaelnw/dsbrigade_test/main', pwd=None)\n",
    "\n",
    "#Rename file\n",
    "os.rename('/home/rafaelnw/dsbrigade_test/main/item.csv',\n",
    "          '/home/rafaelnw/dsbrigade_test/main/item_2016.csv')\n",
    "\n",
    "#Read file\n",
    "item_2016 = pd.read_csv(\"item_2016.csv\",\n",
    "                        header=0,\n",
    "                        low_memory=False,\n",
    "                        usecols=item_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Completed\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "#Defining the zip file URL\n",
    "url = 'http://dados.tce.rs.gov.br/dados/licitacon/licitacao/ano/2017.csv.zip'\n",
    "\n",
    "# Split URL to get the file name\n",
    "filename = url.split('/')[-1]\n",
    "\n",
    "# Downloading the file by sending the request to the URL\n",
    "req = requests.get(url)\n",
    "print('Downloading Completed')\n",
    "\n",
    "# extracting the zip file contents\n",
    "zipfile = zipfile.ZipFile(BytesIO(req.content))\n",
    "zipfile.extract(member='item.csv',\n",
    "                path='/home/rafaelnw/dsbrigade_test/main', pwd=None)\n",
    "\n",
    "#Rename file\n",
    "os.rename('/home/rafaelnw/dsbrigade_test/main/item.csv',\n",
    "          '/home/rafaelnw/dsbrigade_test/main/item_2017.csv')\n",
    "\n",
    "#Read file\n",
    "item_2017 = pd.read_csv(\"item_2017.csv\",\n",
    "                        header=0,\n",
    "                        low_memory=False,\n",
    "                        usecols=item_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Completed\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "#Defining the zip file URL\n",
    "url = 'http://dados.tce.rs.gov.br/dados/licitacon/licitacao/ano/2018.csv.zip'\n",
    "\n",
    "# Split URL to get the file name\n",
    "filename = url.split('/')[-1]\n",
    "\n",
    "# Downloading the file by sending the request to the URL\n",
    "req = requests.get(url)\n",
    "print('Downloading Completed')\n",
    "\n",
    "# extracting the zip file contents\n",
    "zipfile = zipfile.ZipFile(BytesIO(req.content))\n",
    "zipfile.extract(member='item.csv',\n",
    "                path='/home/rafaelnw/dsbrigade_test/main', pwd=None)\n",
    "\n",
    "#Rename file\n",
    "os.rename('/home/rafaelnw/dsbrigade_test/main/item.csv',\n",
    "          '/home/rafaelnw/dsbrigade_test/main/item_2018.csv')\n",
    "\n",
    "#Read file\n",
    "item_2018 = pd.read_csv(\"item_2018.csv\",\n",
    "                        header=0,\n",
    "                        low_memory=False,\n",
    "                        usecols=item_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Completed\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "#Defining the zip file URL\n",
    "url = 'http://dados.tce.rs.gov.br/dados/licitacon/licitacao/ano/2019.csv.zip'\n",
    "\n",
    "# Split URL to get the file name\n",
    "filename = url.split('/')[-1]\n",
    "\n",
    "# Downloading the file by sending the request to the URL\n",
    "req = requests.get(url)\n",
    "print('Downloading Completed')\n",
    "\n",
    "# extracting the zip file contents\n",
    "zipfile = zipfile.ZipFile(BytesIO(req.content))\n",
    "zipfile.extract(member='item.csv',\n",
    "                path='/home/rafaelnw/dsbrigade_test/main', pwd=None)\n",
    "\n",
    "#Rename file\n",
    "os.rename('/home/rafaelnw/dsbrigade_test/main/item.csv',\n",
    "          '/home/rafaelnw/dsbrigade_test/main/item_2019.csv')\n",
    "\n",
    "#Read file\n",
    "item_2019 = pd.read_csv(\"item_2019.csv\",\n",
    "                        header=0,\n",
    "                        low_memory=False,\n",
    "                        usecols=item_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take only first word, remove special char. and lowercase\n",
    "item_2016['DS_ITEM'] = item_2016['DS_ITEM'].str.split(' ').str[0]\n",
    "item_2016['DS_ITEM'] = item_2016['DS_ITEM'].str.normalize('NFKD').str.encode(\n",
    "    'ascii', errors='ignore').str.decode('utf-8')\n",
    "item_2016['DS_ITEM'] = item_2016['DS_ITEM'].str.lower()\n",
    "\n",
    "item_2017['DS_ITEM'] = item_2017['DS_ITEM'].str.split(' ').str[0]\n",
    "item_2017['DS_ITEM'] = item_2017['DS_ITEM'].str.normalize('NFKD').str.encode(\n",
    "    'ascii', errors='ignore').str.decode('utf-8')\n",
    "item_2017['DS_ITEM'] = item_2017['DS_ITEM'].str.lower()\n",
    "\n",
    "item_2018['DS_ITEM'] = item_2018['DS_ITEM'].str.split(' ').str[0]\n",
    "item_2018['DS_ITEM'] = item_2018['DS_ITEM'].str.normalize('NFKD').str.encode(\n",
    "    'ascii', errors='ignore').str.decode('utf-8')\n",
    "item_2018['DS_ITEM'] = item_2018['DS_ITEM'].str.lower()\n",
    "\n",
    "item_2019['DS_ITEM'] = item_2019['DS_ITEM'].str.split(' ').str[0]\n",
    "item_2019['DS_ITEM'] = item_2019['DS_ITEM'].str.normalize('NFKD').str.encode(\n",
    "    'ascii', errors='ignore').str.decode('utf-8')\n",
    "item_2019['DS_ITEM'] = item_2019['DS_ITEM'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take values with counting greater than 2500\n",
    "item_2016_filtered = item_2016.groupby(\n",
    "    'DS_ITEM').filter(lambda x: len(x) > 2500)\n",
    "\n",
    "item_2017_filtered = item_2017.groupby(\n",
    "    'DS_ITEM').filter(lambda x: len(x) > 2500)\n",
    "\n",
    "item_2018_filtered = item_2018.groupby(\n",
    "    'DS_ITEM').filter(lambda x: len(x) > 2500)\n",
    "\n",
    "item_2019_filtered = item_2019.groupby(\n",
    "    'DS_ITEM').filter(lambda x: len(x) > 2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DS_ITEM  Count       Mean  Median  Standard Deviation       Max  Min\n",
      "9    papel   4968  21.346156   4.565           49.786040   2241.00  0.0\n",
      "3   filtro   4139  94.199071  39.000          482.573672  21900.00  0.0\n",
      "13    tubo   3907  82.959132  25.350          271.139594   6010.13  0.0\n",
      "8     oleo   3882  63.187643   8.500          177.774882   2300.00  0.0\n",
      "7     luva   3709  23.349247   4.950          101.394404   2500.00  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2880/1798790231.py:2: FutureWarning: This dataframe has a column name that matches the 'value_name' column name of the resulting Dataframe. In the future this will raise an error, please set the 'value_name' parameter of DataFrame.melt to a unique name.\n",
      "  m_2016 = item_2016_filtered.filter(regex=r'VL_UNITARIO_HOMOLOGADO|DS_ITEM').melt(\n"
     ]
    }
   ],
   "source": [
    "# filter and melt the dataframe\n",
    "m_2016 = item_2016_filtered.filter(regex=r'VL_UNITARIO_HOMOLOGADO|DS_ITEM').melt(\n",
    "    'VL_UNITARIO_HOMOLOGADO', value_name='DS_ITEM')\n",
    "\n",
    "# group and aggregate\n",
    "dct_2016 = {'Count': ('DS_ITEM', 'count'), 'Mean': (\n",
    "    'VL_UNITARIO_HOMOLOGADO', 'mean'), 'Median': ('VL_UNITARIO_HOMOLOGADO', 'median'), \n",
    "    'Standard Deviation': ('VL_UNITARIO_HOMOLOGADO', 'std'), 'Max': ('VL_UNITARIO_HOMOLOGADO', 'max'),\n",
    "    'Min': ('VL_UNITARIO_HOMOLOGADO', 'min')}\n",
    "count_2016 = m_2016.groupby('DS_ITEM', as_index=False).agg(**dct_2016)\n",
    "count_2016.drop([2,10, 11], axis=0, inplace=True)\n",
    "count_2016 = count_2016.sort_values('Count',ascending = False).head(5)\n",
    "print(count_2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DS_ITEM  Count        Mean  Median  Standard Deviation       Max  Min\n",
      "42    pneu  11744  957.846195  619.00          990.963594  11950.00  0.0\n",
      "20  filtro  11150   74.315877   39.00          254.249356  13598.00  0.0\n",
      "37   papel  10834   20.678532    4.69           39.724066   1480.00  0.0\n",
      "35    oleo   8665   91.665985   10.00          258.089969   3304.00  0.0\n",
      "31    luva   7557   23.760196    3.95          138.158004   6654.66  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2880/3792914232.py:2: FutureWarning: This dataframe has a column name that matches the 'value_name' column name of the resulting Dataframe. In the future this will raise an error, please set the 'value_name' parameter of DataFrame.melt to a unique name.\n",
      "  m_2017 = item_2017_filtered.filter(regex=r'VL_UNITARIO_HOMOLOGADO|DS_ITEM').melt(\n"
     ]
    }
   ],
   "source": [
    "# filter and melt the dataframe\n",
    "m_2017 = item_2017_filtered.filter(regex=r'VL_UNITARIO_HOMOLOGADO|DS_ITEM').melt(\n",
    "    'VL_UNITARIO_HOMOLOGADO', value_name='DS_ITEM')\n",
    "\n",
    "# group and aggregate\n",
    "dct_2017 = {'Count': ('DS_ITEM', 'count'), 'Mean': (\n",
    "    'VL_UNITARIO_HOMOLOGADO', 'mean'), 'Median': ('VL_UNITARIO_HOMOLOGADO', 'median'), \n",
    "    'Standard Deviation': ('VL_UNITARIO_HOMOLOGADO', 'std'), 'Max': ('VL_UNITARIO_HOMOLOGADO', 'max'),\n",
    "    'Min': ('VL_UNITARIO_HOMOLOGADO', 'min')}\n",
    "count_2017 = m_2017.groupby('DS_ITEM', as_index=False).agg(**dct_2017)\n",
    "count_2017.drop([17,18,47, 48], axis=0, inplace=True)\n",
    "count_2017 = count_2017.sort_values('Count',ascending = False).head(5)\n",
    "print(count_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2880/3552298216.py:2: FutureWarning: This dataframe has a column name that matches the 'value_name' column name of the resulting Dataframe. In the future this will raise an error, please set the 'value_name' parameter of DataFrame.melt to a unique name.\n",
      "  m_2018 = item_2018_filtered.filter(regex=r'VL_UNITARIO_HOMOLOGADO|DS_ITEM').melt(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DS_ITEM  Count        Mean    Median  Standard Deviation       Max  Min\n",
      "38    pneu  10942  955.154984  609.7000          961.591157   19000.0  0.0\n",
      "33   papel  10884   23.126219    6.0000          102.889797    9221.0  0.0\n",
      "17  filtro  10769   85.590183   43.5000          277.251470   11960.0  0.0\n",
      "48    tubo   8119  186.912224   28.9335         6445.020705  534479.4  0.0\n",
      "31    oleo   8114   95.235688   10.0000          276.210073    4980.0  0.0\n"
     ]
    }
   ],
   "source": [
    "# filter and melt the dataframe\n",
    "m_2018 = item_2018_filtered.filter(regex=r'VL_UNITARIO_HOMOLOGADO|DS_ITEM').melt(\n",
    "    'VL_UNITARIO_HOMOLOGADO', value_name='DS_ITEM')\n",
    "\n",
    "# group and aggregate\n",
    "dct_2018 = {'Count': ('DS_ITEM', 'count'), 'Mean': (\n",
    "    'VL_UNITARIO_HOMOLOGADO', 'mean'), 'Median': ('VL_UNITARIO_HOMOLOGADO', 'median'), \n",
    "    'Standard Deviation': ('VL_UNITARIO_HOMOLOGADO', 'std'), 'Max': ('VL_UNITARIO_HOMOLOGADO', 'max'),\n",
    "    'Min': ('VL_UNITARIO_HOMOLOGADO', 'min')}\n",
    "count_2018 = m_2018.groupby('DS_ITEM', as_index=False).agg(**dct_2018)\n",
    "count_2018.drop([15, 43, 44], axis=0, inplace=True)\n",
    "count_2018 = count_2018.sort_values('Count',ascending = False).head(5)\n",
    "print(count_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DS_ITEM  Count        Mean   Median  Standard Deviation       Max  Min\n",
      "18  filtro  13639   83.721559   37.910          351.378764  14024.92  0.0\n",
      "40    pneu  11495  981.468675  590.000         1036.211847  22140.00  0.0\n",
      "35   papel  10766   22.355177    6.880           42.648848   1400.00  0.0\n",
      "51    tubo   9147  108.863482   30.500          435.619015  19066.00  0.0\n",
      "33    oleo   8518  105.112835   10.945          274.760618   3678.00  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2880/3817435061.py:2: FutureWarning: This dataframe has a column name that matches the 'value_name' column name of the resulting Dataframe. In the future this will raise an error, please set the 'value_name' parameter of DataFrame.melt to a unique name.\n",
      "  m_2019 = item_2019_filtered.filter(regex=r'VL_UNITARIO_HOMOLOGADO|DS_ITEM').melt(\n"
     ]
    }
   ],
   "source": [
    "# filter and melt the dataframe\n",
    "m_2019 = item_2019_filtered.filter(regex=r'VL_UNITARIO_HOMOLOGADO|DS_ITEM').melt(\n",
    "    'VL_UNITARIO_HOMOLOGADO', value_name='DS_ITEM')\n",
    "\n",
    "# group and aggregate\n",
    "dct_2019 = {'Count': ('DS_ITEM', 'count'), 'Mean': (\n",
    "    'VL_UNITARIO_HOMOLOGADO', 'mean'), 'Median': ('VL_UNITARIO_HOMOLOGADO', 'median'),\n",
    "    'Standard Deviation': ('VL_UNITARIO_HOMOLOGADO', 'std'), 'Max': ('VL_UNITARIO_HOMOLOGADO', 'max'),\n",
    "    'Min': ('VL_UNITARIO_HOMOLOGADO', 'min')}\n",
    "count_2019 = m_2019.groupby('DS_ITEM', as_index=False).agg(**dct_2019)\n",
    "count_2019.drop([13, 15, 41, 42, 46], axis=0, inplace=True)\n",
    "count_2019 = count_2019.sort_values('Count',ascending = False).head(5)\n",
    "print(count_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delet unecessary objects\n",
    "del(dct_2016, dct_2018, dct_2019, item_2016, \n",
    "item_2017, item_2018, item_2019, m_2016, m_2017, \n",
    "m_2018, m_2019, req, url, zipfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
