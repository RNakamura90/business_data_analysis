{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take only necessary columns\n",
    "item_columns = [\"DS_ITEM\", \"VL_UNITARIO_HOMOLOGADO\", \"NR_LICITACAO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Completed\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "#Defining the zip file URL\n",
    "url = 'http://dados.tce.rs.gov.br/dados/licitacon/licitacao/ano/2016.csv.zip'\n",
    "\n",
    "# Split URL to get the file name\n",
    "filename = url.split('/')[-1]\n",
    "\n",
    "# Downloading the file by sending the request to the URL\n",
    "req= requests.get(url)\n",
    "print('Downloading Completed')\n",
    "\n",
    "# extracting the zip file contents\n",
    "zipfile = zipfile.ZipFile(BytesIO(req.content))\n",
    "zipfile.extract(member='item.csv',\n",
    "                path='/home/rafaelnw/dsbrigade_test/main', pwd=None)\n",
    "\n",
    "#Rename file\n",
    "os.rename('/home/rafaelnw/dsbrigade_test/main/item.csv',\n",
    "          '/home/rafaelnw/dsbrigade_test/main/item_2016.csv')\n",
    "\n",
    "#Read file\n",
    "item_2016 = pd.read_csv(\"item_2016.csv\",\n",
    "                        header=0,\n",
    "                        low_memory=False,\n",
    "                        usecols=item_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Completed\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "#Defining the zip file URL\n",
    "url = 'http://dados.tce.rs.gov.br/dados/licitacon/licitacao/ano/2017.csv.zip'\n",
    "\n",
    "# Split URL to get the file name\n",
    "filename = url.split('/')[-1]\n",
    "\n",
    "# Downloading the file by sending the request to the URL\n",
    "req = requests.get(url)\n",
    "print('Downloading Completed')\n",
    "\n",
    "# extracting the zip file contents\n",
    "zipfile = zipfile.ZipFile(BytesIO(req.content))\n",
    "zipfile.extract(member='item.csv',\n",
    "                path='/home/rafaelnw/dsbrigade_test/main', pwd=None)\n",
    "\n",
    "#Rename file\n",
    "os.rename('/home/rafaelnw/dsbrigade_test/main/item.csv',\n",
    "          '/home/rafaelnw/dsbrigade_test/main/item_2017.csv')\n",
    "\n",
    "#Read file\n",
    "item_2017 = pd.read_csv(\"item_2017.csv\",\n",
    "                        header=0,\n",
    "                        low_memory=False,\n",
    "                        usecols=item_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Completed\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "#Defining the zip file URL\n",
    "url = 'http://dados.tce.rs.gov.br/dados/licitacon/licitacao/ano/2018.csv.zip'\n",
    "\n",
    "# Split URL to get the file name\n",
    "filename = url.split('/')[-1]\n",
    "\n",
    "# Downloading the file by sending the request to the URL\n",
    "req = requests.get(url)\n",
    "print('Downloading Completed')\n",
    "\n",
    "# extracting the zip file contents\n",
    "zipfile = zipfile.ZipFile(BytesIO(req.content))\n",
    "zipfile.extract(member='item.csv',\n",
    "                path='/home/rafaelnw/dsbrigade_test/main', pwd=None)\n",
    "\n",
    "#Rename file\n",
    "os.rename('/home/rafaelnw/dsbrigade_test/main/item.csv',\n",
    "          '/home/rafaelnw/dsbrigade_test/main/item_2018.csv')\n",
    "\n",
    "#Read file\n",
    "item_2018 = pd.read_csv(\"item_2018.csv\",\n",
    "                        header=0,\n",
    "                        low_memory=False,\n",
    "                        usecols=item_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Completed\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "#Defining the zip file URL\n",
    "url = 'http://dados.tce.rs.gov.br/dados/licitacon/licitacao/ano/2019.csv.zip'\n",
    "\n",
    "# Split URL to get the file name\n",
    "filename = url.split('/')[-1]\n",
    "\n",
    "# Downloading the file by sending the request to the URL\n",
    "req = requests.get(url)\n",
    "print('Downloading Completed')\n",
    "\n",
    "# extracting the zip file contents\n",
    "zipfile = zipfile.ZipFile(BytesIO(req.content))\n",
    "zipfile.extract(member='item.csv',\n",
    "                path='/home/rafaelnw/dsbrigade_test/main', pwd=None)\n",
    "\n",
    "#Rename file\n",
    "os.rename('/home/rafaelnw/dsbrigade_test/main/item.csv',\n",
    "          '/home/rafaelnw/dsbrigade_test/main/item_2019.csv')\n",
    "\n",
    "#Read file\n",
    "item_2019 = pd.read_csv(\"item_2019.csv\",\n",
    "                        header=0,\n",
    "                        low_memory=False,\n",
    "                        usecols=item_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take only first word, remove special char. and lowercase\n",
    "item_2016['DS_ITEM'] = item_2016['DS_ITEM'].str.split(' ').str[0]\n",
    "item_2016['DS_ITEM'] = item_2016['DS_ITEM'].str.normalize('NFKD').str.encode(\n",
    "    'ascii', errors='ignore').str.decode('utf-8')\n",
    "item_2016['DS_ITEM'] = item_2016['DS_ITEM'].str.lower()\n",
    "\n",
    "item_2017['DS_ITEM'] = item_2017['DS_ITEM'].str.split(' ').str[0]\n",
    "item_2017['DS_ITEM'] = item_2017['DS_ITEM'].str.normalize('NFKD').str.encode(\n",
    "    'ascii', errors='ignore').str.decode('utf-8')\n",
    "item_2017['DS_ITEM'] = item_2017['DS_ITEM'].str.lower()\n",
    "\n",
    "item_2018['DS_ITEM'] = item_2018['DS_ITEM'].str.split(' ').str[0]\n",
    "item_2018['DS_ITEM'] = item_2018['DS_ITEM'].str.normalize('NFKD').str.encode(\n",
    "    'ascii', errors='ignore').str.decode('utf-8')\n",
    "item_2018['DS_ITEM'] = item_2018['DS_ITEM'].str.lower()\n",
    "\n",
    "item_2019['DS_ITEM'] = item_2019['DS_ITEM'].str.split(' ').str[0]\n",
    "item_2019['DS_ITEM'] = item_2019['DS_ITEM'].str.normalize('NFKD').str.encode(\n",
    "    'ascii', errors='ignore').str.decode('utf-8')\n",
    "item_2019['DS_ITEM'] = item_2019['DS_ITEM'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take values with counting greater than 2500\n",
    "item_2016_filtered = item_2016.groupby(\n",
    "    'DS_ITEM').filter(lambda x: len(x) > 2500)\n",
    "\n",
    "item_2017_filtered = item_2017.groupby(\n",
    "    'DS_ITEM').filter(lambda x: len(x) > 2500)\n",
    "\n",
    "item_2018_filtered = item_2018.groupby(\n",
    "    'DS_ITEM').filter(lambda x: len(x) > 2500)\n",
    "\n",
    "item_2019_filtered = item_2019.groupby(\n",
    "    'DS_ITEM').filter(lambda x: len(x) > 2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1954/4216405018.py:2: FutureWarning: This dataframe has a column name that matches the 'value_name' column name of the resulting Dataframe. In the future this will raise an error, please set the 'value_name' parameter of DataFrame.melt to a unique name.\n",
      "  m_2016 = item_2016_filtered.filter(regex=r'VL_UNITARIO_HOMOLOGADO|DS_ITEM').melt(\n"
     ]
    }
   ],
   "source": [
    "# filter and melt the dataframe\n",
    "m_2016 = item_2016_filtered.filter(regex=r'VL_UNITARIO_HOMOLOGADO|DS_ITEM').melt(\n",
    "    'VL_UNITARIO_HOMOLOGADO', value_name='DS_ITEM')\n",
    "\n",
    "# group and aggregate\n",
    "dct_2016 = {'Count': ('DS_ITEM', 'count'), 'Mean': (\n",
    "    'VL_UNITARIO_HOMOLOGADO', 'mean'), 'Median': ('VL_UNITARIO_HOMOLOGADO', 'median'), \n",
    "    'Standard Deviation': ('VL_UNITARIO_HOMOLOGADO', 'std'), 'Max': ('VL_UNITARIO_HOMOLOGADO', 'max'),\n",
    "    'Min': ('VL_UNITARIO_HOMOLOGADO', 'min')}\n",
    "count_2016 = m_2016.groupby('DS_ITEM', as_index=False).agg(**dct_2016)\n",
    "count_2016.drop([2,10], axis=0, inplace=True)\n",
    "count_2016 = count_2016.sort_values('Count',ascending = False).head(5)\n",
    "print(count_2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1954/3524263072.py:2: FutureWarning: This dataframe has a column name that matches the 'value_name' column name of the resulting Dataframe. In the future this will raise an error, please set the 'value_name' parameter of DataFrame.melt to a unique name.\n",
      "  m_2017 = item_2017_filtered.filter(regex=r'VL_UNITARIO_HOMOLOGADO|DS_ITEM').melt(\n"
     ]
    }
   ],
   "source": [
    "# filter and melt the dataframe\n",
    "m_2017 = item_2017_filtered.filter(regex=r'VL_UNITARIO_HOMOLOGADO|DS_ITEM').melt(\n",
    "    'VL_UNITARIO_HOMOLOGADO', value_name='DS_ITEM')\n",
    "\n",
    "# group and aggregate\n",
    "dct_2017 = {'Count': ('DS_ITEM', 'count'), 'Mean': (\n",
    "    'VL_UNITARIO_HOMOLOGADO', 'mean'), 'Median': ('VL_UNITARIO_HOMOLOGADO', 'median'), \n",
    "    'Standard Deviation': ('VL_UNITARIO_HOMOLOGADO', 'std'), 'Max': ('VL_UNITARIO_HOMOLOGADO', 'max'),\n",
    "    'Min': ('VL_UNITARIO_HOMOLOGADO', 'min')}\n",
    "count_2017 = m_2017.groupby('DS_ITEM', as_index=False).agg(**dct_2017)\n",
    "count_2017.drop([18,48], axis=0, inplace=True)\n",
    "count_2017 = count_2017.sort_values('Count',ascending = False).head(5)\n",
    "print(count_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DS_ITEM  Count        Mean    Median  Standard Deviation       Max  Min\n",
      "38    pneu  10942  955.154984  609.7000          961.591157   19000.0  0.0\n",
      "33   papel  10884   23.126219    6.0000          102.889797    9221.0  0.0\n",
      "17  filtro  10769   85.590183   43.5000          277.251470   11960.0  0.0\n",
      "48    tubo   8119  186.912224   28.9335         6445.020705  534479.4  0.0\n",
      "31    oleo   8114   95.235688   10.0000          276.210073    4980.0  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1954/3552298216.py:2: FutureWarning: This dataframe has a column name that matches the 'value_name' column name of the resulting Dataframe. In the future this will raise an error, please set the 'value_name' parameter of DataFrame.melt to a unique name.\n",
      "  m_2018 = item_2018_filtered.filter(regex=r'VL_UNITARIO_HOMOLOGADO|DS_ITEM').melt(\n"
     ]
    }
   ],
   "source": [
    "# filter and melt the dataframe\n",
    "m_2018 = item_2018_filtered.filter(regex=r'VL_UNITARIO_HOMOLOGADO|DS_ITEM').melt(\n",
    "    'VL_UNITARIO_HOMOLOGADO', value_name='DS_ITEM')\n",
    "\n",
    "# group and aggregate\n",
    "dct_2018 = {'Count': ('DS_ITEM', 'count'), 'Mean': (\n",
    "    'VL_UNITARIO_HOMOLOGADO', 'mean'), 'Median': ('VL_UNITARIO_HOMOLOGADO', 'median'), \n",
    "    'Standard Deviation': ('VL_UNITARIO_HOMOLOGADO', 'std'), 'Max': ('VL_UNITARIO_HOMOLOGADO', 'max'),\n",
    "    'Min': ('VL_UNITARIO_HOMOLOGADO', 'min')}\n",
    "count_2018 = m_2018.groupby('DS_ITEM', as_index=False).agg(**dct_2018)\n",
    "count_2018.drop([15, 43, 44], axis=0, inplace=True)\n",
    "count_2018 = count_2018.sort_values('Count',ascending = False).head(5)\n",
    "print(count_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        DS_ITEM  Count           Mean      Median  Standard Deviation  \\\n",
      "46      servico  14631   34663.232491    90.24905        1.387544e+06   \n",
      "18       filtro  13639      83.721559    37.91000        3.513788e+02   \n",
      "15  contratacao  12161  113373.595958  1200.00000        1.066480e+06   \n",
      "40         pneu  11495     981.468675   590.00000        1.036212e+03   \n",
      "35        papel  10766      22.355177     6.88000        4.264885e+01   \n",
      "\n",
      "             Max    Min  \n",
      "46  1.131003e+08  -5.21  \n",
      "18  1.402492e+04   0.00  \n",
      "15  4.667884e+07 -95.00  \n",
      "40  2.214000e+04   0.00  \n",
      "35  1.400000e+03   0.00  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1954/1695252283.py:2: FutureWarning: This dataframe has a column name that matches the 'value_name' column name of the resulting Dataframe. In the future this will raise an error, please set the 'value_name' parameter of DataFrame.melt to a unique name.\n",
      "  m_2019 = item_2019_filtered.filter(regex=r'VL_UNITARIO_HOMOLOGADO|DS_ITEM').melt(\n"
     ]
    }
   ],
   "source": [
    "# filter and melt the dataframe\n",
    "m_2019 = item_2019_filtered.filter(regex=r'VL_UNITARIO_HOMOLOGADO|DS_ITEM').melt(\n",
    "    'VL_UNITARIO_HOMOLOGADO', value_name='DS_ITEM')\n",
    "\n",
    "# group and aggregate\n",
    "dct_2019 = {'Count': ('DS_ITEM', 'count'), 'Mean': (\n",
    "    'VL_UNITARIO_HOMOLOGADO', 'mean'), 'Median': ('VL_UNITARIO_HOMOLOGADO', 'median'),\n",
    "    'Standard Deviation': ('VL_UNITARIO_HOMOLOGADO', 'std'), 'Max': ('VL_UNITARIO_HOMOLOGADO', 'max'),\n",
    "    'Min': ('VL_UNITARIO_HOMOLOGADO', 'min')}\n",
    "count_2019 = m_2019.groupby('DS_ITEM', as_index=False).agg(**dct_2019)\n",
    "count_2019.drop([13, 41, 42], axis=0, inplace=True)\n",
    "count_2019 = count_2019.sort_values('Count',ascending = False).head(5)\n",
    "print(count_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delet unecessary objects\n",
    "del(dct_2016, dct_2018, dct_2019, item_2016, \n",
    "item_2017, item_2018, item_2019, m_2016, m_2017, \n",
    "m_2018, m_2019, req, url, zipfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
